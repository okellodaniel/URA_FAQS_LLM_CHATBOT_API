{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84094aee-0d4a-4074-8407-fdddee62aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638b4a40-689b-43b3-8241-725ffbb1ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL and file for saving output\n",
    "url = \"https://ura.go.ug/\"\n",
    "json_export = 'ura_faqs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6869b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_webdriver(headless=True):\n",
    "    \"\"\"\n",
    "    Initialize the Selenium WebDriver with optional headless mode.\n",
    "    \"\"\"\n",
    "    print(\"Initializing WebDriver.\")\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument('--headless') \n",
    "        options.add_argument('--disable-gpu')\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')  \n",
    "        options.add_argument('--remote-debugging-port=9222')  \n",
    "        options.add_argument('--disable-extensions')\n",
    "        options.add_argument('--disable-infobars')\n",
    "        options.add_argument('--disable-browser-side-navigation')\n",
    "        options.add_argument('--disable-features=VizDisplayCompositor')\n",
    "        options.add_argument('--window-size=1920,1080')  \n",
    "        options.add_argument('--disable-setuid-sandbox')\n",
    "    try:\n",
    "        service = Service(verbose=True)\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        print(\"WebDriver initialized successfully.\")\n",
    "        return driver\n",
    "    except WebDriverException as e:\n",
    "        print(f\"Failed to initialize WebDriver: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f6b84d-9a5c-4439-8acd-029f10179791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_section_name(section_name):\n",
    "    \"\"\"\n",
    "    Remove unwanted characters and whitespaces\n",
    "    \"\"\"\n",
    "    cleaned_name = re.sub(r\"[«»]\", \"\", section_name).strip()\n",
    "    cleaned_name = re.sub(r\"\\s+\", \" \", cleaned_name)\n",
    "    return cleaned_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa71249-09fa-40c1-8d79-06b3fb7fca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAQ dropdown button manipulator\n",
    "def click_faq_dropdown(driver):\n",
    "    try:\n",
    "        print(f\"Opening URL: {url}\")\n",
    "        driver.get(url)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Wait for FAQ button to be clickable\n",
    "        faq_button = wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'dropdown-toggle') and contains(., 'FAQs')]\"))\n",
    "        )\n",
    "        print(\"Clicking FAQ dropdown button.\")\n",
    "        faq_button.click()\n",
    "\n",
    "        # dropdown menu is visible\n",
    "        wait.until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, \".faqs-global-sec-menu-items\"))\n",
    "        )\n",
    "        \n",
    "        print(\"FAQ dropdown displayed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to click FAQ dropdown: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9292a54c-c674-4823-aa14-33e9a1a3410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract FAQ links\n",
    "def extract_faq_links(driver):\n",
    "    try:\n",
    "        print(\"Extracting FAQ section links from the dropdown.\")\n",
    "        # Trace top-level drop down items\n",
    "        dropdown_menu = driver.find_element(By.CSS_SELECTOR, \".faqs-global-sec-menu-items\")\n",
    "        faq_items = dropdown_menu.find_elements(By.XPATH, \"./li\")\n",
    "\n",
    "        # Extract links and section names\n",
    "        faq_urls = []\n",
    "        for item in faq_items:\n",
    "            try:\n",
    "                link = item.find_element(By.TAG_NAME, 'a')\n",
    "                raw_section_name = link.text.strip()\n",
    "                section_url = link.get_attribute('href')\n",
    "\n",
    "                if link.get_attribute('data-bs-toggle') == 'dropdown':\n",
    "                    parent_section_name = clean_section_name(raw_section_name)\n",
    "                    print(f\"Found parent section: '{parent_section_name}' with URL: {section_url}\")\n",
    "\n",
    "                    # Find the nested submenu\n",
    "                    try:\n",
    "                        submenu = item.find_element(By.CSS_SELECTOR, \"ul.submenu\")\n",
    "                        submenu_links = submenu.find_elements(By.TAG_NAME, 'a')\n",
    "                        for submenu_link in submenu_links:\n",
    "                            submenu_section_name = parent_section_name\n",
    "                            submenu_url = submenu_link.get_attribute('href')\n",
    "                            faq_urls.append({\"url\": submenu_url, \"section\": submenu_section_name})\n",
    "                            print(f\"Found subsection: '{submenu_section_name}' with URL: {submenu_url}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"No submenu found for parent section: '{parent_section_name}' - {e}\")\n",
    "                else:\n",
    "                    # It's an actual FAQ link\n",
    "                    cleaned_section_name = clean_section_name(raw_section_name)\n",
    "                    if cleaned_section_name:  \n",
    "                        faq_urls.append({\"url\": section_url, \"section\": cleaned_section_name})\n",
    "                        print(f\"Found section: '{cleaned_section_name}' with URL: {section_url}\")\n",
    "                    else:\n",
    "                        print(f\"Found section link with empty name - URL: {section_url}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process a dropdown item - {e}\")\n",
    "\n",
    "        print(f\"Total FAQ sections found: {len(faq_urls)}\")\n",
    "        return faq_urls\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract FAQ links: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7aff980-7dd1-42e3-9f01-8c93c69c434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract FAQs from a single page\n",
    "def extract_faqs_from_page(driver, page_url, section_name):\n",
    "    try:\n",
    "        print(f\"Extracting FAQs from section: {section_name} - URL: {page_url}\")\n",
    "        driver.get(page_url)\n",
    "\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'accordion-header'))\n",
    "        )\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        html_content = driver.page_source\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        crude_faqs = []\n",
    "        headings = soup.find_all('h2', {'class': 'accordion-header'})\n",
    "\n",
    "        for heading in headings:\n",
    "            if 'flush' in heading.get('id',''):\n",
    "                question = heading.find('button', class_='accordion-button').get_text(strip=True)\n",
    "\n",
    "                question_cleaned = re.sub(r\"^\\d+\\.?\\s*\", \"\", question)\n",
    "                \n",
    "                collapse_id = heading.find('button')['data-bs-target'].replace('#', '')\n",
    "                answer_div = soup.find('div', {'id': collapse_id})\n",
    "\n",
    "                if answer_div:\n",
    "                    answer = answer_div.find('div', class_='accordion-body').get_text(strip=True)\n",
    "                    faqs.append({\"Question\": question_cleaned, \"Answer\": answer, \"Section\": section_name})\n",
    "                    print(f\"Extracted FAQ - Question: {question_cleaned}, Section: {section_name}\")\n",
    "        \n",
    "        faqs = []\n",
    "\n",
    "        for faq in crude_faqs:\n",
    "            if faq['question'] == '' and faq['answer'] == '':\n",
    "                continue\n",
    "            faqs.append(faq)\n",
    "\n",
    "        print(f\"Extracted {len(faqs)} FAQs from section: {section_name}\")\n",
    "        return faqs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract FAQs from {page_url}: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b212c1-0b3a-4182-873b-3ae505e4314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extracted FAQs to a JSON file\n",
    "def save_faqs_to_json(faqs, filename=json_export):\n",
    "    try:\n",
    "        print(f\"Saving {len(faqs)} FAQs to JSON file: {filename}\")\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(faqs, file, indent=4)\n",
    "        print(f\"FAQs successfully saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save FAQs to JSON: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9869c067-4181-4598-8adb-5b71d1a0f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to scrape all FAQs\n",
    "def scrape_all_faqs(headless=True):\n",
    "    print(\"Starting FAQ scraping process.\")\n",
    "    driver=None\n",
    "    try:\n",
    "        driver = init_webdriver(headless=headless)\n",
    "        click_faq_dropdown(driver)\n",
    "        faq_urls = extract_faq_links(driver)\n",
    "        print(f\"Collected {len(faq_urls)} FAQ URLs.\")\n",
    "\n",
    "        all_faqs = []\n",
    "        for page in faq_urls:\n",
    "            faqs = extract_faqs_from_page(driver, page[\"url\"], page[\"section\"])\n",
    "            all_faqs.extend(faqs)\n",
    "\n",
    "        save_faqs_to_json(all_faqs)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during FAQ scraping: {e}\")\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "            print(\"WebDriver closed.\")\n",
    "        else:\n",
    "            print(\"WebDriver was not initialized; skipping quit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57730ee8-d0a2-495f-806f-7e4ca94b5d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FAQ scraping process.\n",
      "Initializing WebDriver.\n",
      "Failed to initialize WebDriver: Message: session not created: Chrome failed to start: exited normally.\n",
      "  (chrome not reachable)\n",
      "  (The process started from chrome location /home/daniel/.cache/selenium/chrome/linux64/129.0.6668.58/chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)\n",
      "Stacktrace:\n",
      "#0 0x60186067713a <unknown>\n",
      "#1 0x60186035d5e0 <unknown>\n",
      "#2 0x601860395921 <unknown>\n",
      "#3 0x6018603912c5 <unknown>\n",
      "#4 0x6018603dddf6 <unknown>\n",
      "#5 0x6018603dd446 <unknown>\n",
      "#6 0x6018603d18c3 <unknown>\n",
      "#7 0x60186039f6b3 <unknown>\n",
      "#8 0x6018603a068e <unknown>\n",
      "#9 0x601860641b3b <unknown>\n",
      "#10 0x601860645ac1 <unknown>\n",
      "#11 0x60186062e335 <unknown>\n",
      "#12 0x601860646642 <unknown>\n",
      "#13 0x60186061349f <unknown>\n",
      "#14 0x601860666038 <unknown>\n",
      "#15 0x601860666203 <unknown>\n",
      "#16 0x601860675f8c <unknown>\n",
      "#17 0x78f541e9ca94 <unknown>\n",
      "#18 0x78f541f29c3c <unknown>\n",
      "\n",
      "Opening URL: https://ura.go.ug/\n",
      "Failed to click FAQ dropdown: 'NoneType' object has no attribute 'get'\n",
      "Error during FAQ scraping: 'NoneType' object has no attribute 'get'\n",
      "WebDriver was not initialized; skipping quit.\n"
     ]
    }
   ],
   "source": [
    "scrape_all_faqs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205bfa85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
